# AI Translation Workflow System - Project Showcase

> **AI-Powered Translation Workflow System with Advanced Prompt Engineering**  
> Chinese-Arabic bidirectional translation system powered by Claude (Anthropic), featuring dynamic prompt assembly, analysis reuse architecture, and quality-tiered workflows

---

## üìã Project Overview

**Background**: Build a professional-grade Chinese-Arabic bidirectional translation system that provides differentiated translation quality and analysis depth for various scenarios (casual communication, business documents, important contracts).

**Core Value**:
- üéØ **Quality Tiers**: Three translation quality levels (Fast/Standard/Premium) for different time/precision requirements
- üß† **Intelligent Analysis**: Modular analysis function balls providing multi-dimensional insights (text features, terminology, translation strategies)
- üí∞ **Cost Optimization**: Dynamic prompts + analysis reuse mechanism **reducing 30-50% redundant token consumption**
- üîÑ **Two-Step Translation**: Decoupled analysis/strategy and translation execution for improved stability and controllability

**Technical Role**: Responsible for Prompt Engineering, translation workflow design, analysis reuse architecture, and end-to-end logging system

---

## üé® Core Technical Highlights

### 1. Quality-Tiered Translation Workflow

Designed three quality tiers, each with distinct prompt strategies:

| Quality Tier | Use Case | Prompt Strategy | Output Characteristics |
|-------------|----------|----------------|----------------------|
| **Fast** | Casual communication, urgent processing | Single-step simplified prompt | Concise results, optimized speed |
| **Standard** | Business, academic, content creation | **Two-step prompt chain** | Detailed analysis + polished translation |
| **Premium** | Important documents, formal occasions | Multi-round refinement prompt | Cultural adaptation optimization |

#### Two-Step Design in Standard Mode

```
Step 1: Analysis/Strategy Prompt
‚îú‚îÄ Input: Source text + Translation requirements + Existing analysis (optional)
‚îú‚îÄ Output: Text features, terminology strategies, translation advice
‚îî‚îÄ Role: Translation analysis and strategy expert

Step 2: Translation Execution Prompt
‚îú‚îÄ Input: Source text + Step 1 analysis report
‚îú‚îÄ Output: Initial draft ‚Üí Refinement ‚Üí Final translation
‚îî‚îÄ Role: Senior professional translator
```

**Value**: Decoupling strategy from output facilitates tuning, debugging, and quality retrospection

---

### 2. Dynamic Prompt Assembly Engine

Dynamically constructs prompts based on user input, avoiding wasted tokens on empty fields:

#### Implementation Mechanism

```javascript
// Detect user-filled translation requirements
function hasTranslationRequirements(requirements) {
  return {
    hasIntent: requirements.intent && requirements.intent.trim() !== '',
    hasReference: requirements.reference && requirements.reference.trim() !== '',
    hasDirectRequest: requirements.directRequest && requirements.directRequest.trim() !== ''
  }
}

// Dynamically build translation guidance section
function buildTranslationGuidance(requirements, hasRequirements) {
  let guidance = '###Translation Guidance\n'
  if (hasRequirements.hasIntent) {
    guidance += `- Translation intent/audience: ${requirements.intent}\n`
  }
  // ... only add fields with input
  return guidance
}

// Dynamically build output format (remove existing analysis fields)
function buildModifiedOutputFormat(hasRequirements, analysisForTranslation) {
  let outputFormat = '{'
  // Only add missing fields to output schema
  if (!analysisForTranslation.text_characteristics) {
    outputFormat += `"text_characteristics": "..."`
  }
  // ...
  return outputFormat
}
```

#### Token Savings Effect

| Scenario | Without Requirements | With All Requirements | Savings Range |
|---------|---------------------|---------------------|---------------|
| Fast Prompt | ~200 tokens | ~280 tokens | **Save 40-80 tokens** |
| Standard Prompt | ~350 tokens | ~450 tokens | **Save 20-40 tokens** |

**Value**: Reduce token consumption per call while maintaining full functionality

---

### 3. Analysis Reuse Architecture

Implements "analyze-first, translate-later" usage pattern to avoid repeated analysis consumption:

#### Data Flow Design

```
User Action: Function Ball Analysis ‚Üí Standard Translation
                ‚Üì
Frontend Store: Incrementally store analysis results + validate text consistency
                ‚Üì
Translation Request: Carries analysisForTranslation field
                ‚Üì
Backend Analysis Prompt: Insert "#Existing Analysis" section + dynamically prune output schema
                ‚Üì
Result Merging: Prioritize existing analysis, supplement with newly generated content
                ‚Üì
Translation Prompt: Use merged complete analysis report
```

#### Key Code Implementation

**Frontend Storage (Pinia Store)**

```javascript
// Incrementally accumulate analysis results, supporting grouped analysis
storeAnalysisForTranslation(analysisData, text) {
  this.lastAnalyzedText = text.trim()
  
  // Accumulate various analysis results
  if (analysisData.text_characteristics) {
    this.analysisForTranslation.text_characteristics = analysisData.text_characteristics
  }
  if (analysisData.terminology_idioms_analysis) {
    // Merge terminology without overwriting existing terms
    this.analysisForTranslation.terminology_idioms_analysis = {
      ...this.analysisForTranslation.terminology_idioms_analysis,
      ...analysisData.terminology_idioms_analysis
    }
  }
  // ...
}

// Validate text consistency before passing to translation interface
getAnalysisForTranslation(currentText) {
  if (this.lastAnalyzedText === currentText && this.hasAnalysis()) {
    return this.analysisForTranslation
  }
  return null
}
```

**Backend Analysis Prompt Construction**

```javascript
function buildStandardAnalysisPrompt(text, ..., analysisForTranslation) {
  let existingAnalysisSection = ''
  
  if (analysisForTranslation && hasValidAnalysis(analysisForTranslation)) {
    // Build existing analysis section
    existingAnalysisSection = `
#Existing Analysis
text_characteristics: "${analysisForTranslation.text_characteristics}"
terminology/idioms_analysis: ${JSON.stringify(analysisForTranslation.terminology_idioms_analysis)}
...
`
    // Adjust workflow instructions
    workflowSection = `##Workflow (skip steps already covered by existing analysis)
1. Analyze source text characteristics...
...`
    
    // Dynamically remove output requirements for existing analysis fields
    outputFormatSection = buildModifiedOutputFormat(hasRequirements, analysisForTranslation)
  }
  
  return prompt
}
```

**Backend Result Merging**

```javascript
// Merge existing analysis with analysis prompt output
finalAnalysisReport = {
  // Prioritize existing analysis; use analysis prompt output if empty
  text_characteristics: 
    analysisForTranslation.text_characteristics || analysisResult.text_characteristics,
  terminology_idioms_analysis: 
    analysisForTranslation.terminology_idioms_analysis || analysisResult.terminology_idioms_analysis,
  initial_translation_strategy: 
    analysisForTranslation.initial_translation_strategy || analysisResult.initial_translation_strategy,
  // ...
  // Retain other useful fields from analysis prompt
  ...(analysisResult.underGuidanceStrategy && { underGuidanceStrategy: analysisResult.underGuidanceStrategy }),
  ...(analysisResult.final_translate_advice && { final_translate_advice: analysisResult.final_translate_advice })
}
```

#### Precise Field Mapping

Implemented precise mapping between 6 function ball analysis outputs and translation prompt fields:

| Function Ball | Output Field | Translation Prompt Field |
|--------------|-------------|-------------------------|
| Text Features | `text_characteristics_for_model` | `text_characteristics` |
| Terminology/Idioms | `terminology/idioms_analysis` | `terminology_idioms_analysis` |
| Translation Strategy | `initial_translation_strategy_for_model` | `initial_translation_strategy` |
| Intent/Audience | `intent/audience_analysis_for_model` | `intent_audience_analysis` |
| Reference Style | `reference_analysis_for_model` | `reference_translation_analysis` |
| Direct Request | `direct_instruction_analysis_for_model` | `direct_instruction_analysis` |

**Value**: In standard translation scenarios, reduces **30-50% of analysis-related token consumption** and improves response speed

---

### 4. Function Ball Analysis System

Designed 6 independent analysis modules (function balls) supporting flexible combinations and grouped execution:

#### Function Ball List

1. **Text Features Analysis**: Text type, register style, domain, sentiment, pragmatic function
2. **Terminology/Idioms Analysis**: Professional term identification, localized idioms, extended knowledge
3. **Translation Strategy**: Initial translation strategies, progressive recommendations
4. **Intent/Audience Analysis**: Impact of translation intent and target audience on strategy
5. **Reference Style Analysis**: Learning characteristics from reference translations
6. **Direct Request Analysis**: Understanding and implementing user's direct requirements

#### Grouped/Streaming Analysis

Supports grouping multiple function balls (2/group or 3/group) for parallel processing with SSE streaming:

```javascript
// Streaming grouped analysis endpoint
router.post('/analyze-with-balls-streaming', async (req, res) => {
  // Set SSE response headers
  res.setHeader('Content-Type', 'text/event-stream')
  
  // Group processing
  const groups = []
  for (let i = 0; i < selectedBalls.length; i += groupSize) {
    groups.push(selectedBalls.slice(i, i + groupSize))
  }
  
  // Process each group sequentially, return results in real-time
  for (let i = 0; i < groups.length; i++) {
    const group = groups[i]
    
    // Send start status
    res.write(`data: ${JSON.stringify({ type: 'group_start', groupIndex: i + 1 })}\n\n`)
    
    // Call API for analysis
    const result = await analyzeGroup(group)
    
    // Send completion result
    res.write(`data: ${JSON.stringify({ 
      type: 'group_complete', 
      groupIndex: i + 1,
      data: result 
    })}\n\n`)
  }
  
  // Send final completion status
  res.write(`data: ${JSON.stringify({ type: 'complete', mergedResult })}\n\n`)
  res.end()
})
```

**Frontend Real-time Display**

```javascript
// Frontend listens to streaming progress
const enhancedOnProgress = (progressData) => {
  if (progressData.type === 'group_complete') {
    // Display results immediately upon group completion
    displayGroupResult(progressData.data)
    // Store to Store for translation use
    translationStore.storeAnalysisForTranslation(progressData.data, text)
  }
}

await translationStore.analyzeTextWithBallsStreaming(
  analysisRequest, 
  groupSize, 
  enhancedOnProgress
)
```

**Value**: Improved UX (analyze-while-displaying), enhanced explainability, flexible analysis combinations

---

### 5. Engineering & Observability

#### Primary + Fallback Model Strategy

```javascript
const MODEL_CONFIG = {
  primary: 'claude-sonnet-4-20250514',
  fallback: 'claude-3-5-sonnet-20241022',
  maxTokens: 4000,
  temperature: 0.3
}

async function callClaudeAPI(prompt, retryWithFallback = true) {
  try {
    // Try primary model first
    const message = await client.messages.create({ 
      model: MODEL_CONFIG.primary, 
      ... 
    })
    global.logToFile('info', 'Primary model success', { model, duration })
    return message.content[0].text
  } catch (primaryError) {
    global.logToFile('error', 'Primary model failed', { error: primaryError.message })
    
    if (retryWithFallback) {
      try {
        // Use fallback model
        const message = await client.messages.create({ 
          model: MODEL_CONFIG.fallback, 
          ... 
        })
        global.logToFile('info', 'Fallback model success', { model, duration })
        return message.content[0].text
      } catch (fallbackError) {
        global.logToFile('error', 'Fallback model failed', { error: fallbackError.message })
        throw new Error(`Translation service unavailable: primary failed, fallback failed`)
      }
    }
  }
}
```

#### End-to-End Logging System

**Log Persistence**

```javascript
// Automatically create log files by date
function logToFile(level, message, data = null) {
  const timestamp = new Date().toISOString()
  const logEntry = { timestamp, level, message, data }
  
  const logFile = path.join(logDir, `${new Date().toISOString().split('T')[0]}.log`)
  fs.appendFileSync(logFile, JSON.stringify(logEntry) + '\n')
  
  // Output to console simultaneously (with timing highlights)
  console.log(`[${timestamp}] ${level.toUpperCase()}: ${message}`, data)
}
```

**Full Chain Recording**

- API request input/output
- Prompt construction content
- Claude raw responses
- Parsing results
- Per-step timing (millisecond precision)
- Error stacks

**Log Viewing API**

```javascript
app.get('/api/logs', (req, res) => {
  const date = req.query.date || new Date().toISOString().split('T')[0]
  const logFile = path.join(logDir, `${date}.log`)
  
  if (fs.existsSync(logFile)) {
    const logs = fs.readFileSync(logFile, 'utf8')
      .split('\n')
      .filter(line => line.trim())
      .map(line => JSON.parse(line))
      .reverse() // Latest logs first
    
    res.json({ success: true, data: logs })
  }
})
```

**Value**: Improved production troubleshooting efficiency, supports quality retrospection and prompt optimization iteration

---

## üèóÔ∏è Technical Architecture

### Tech Stack

**Frontend**
- Vue 3 + Composition API
- Pinia (State Management)
- Element Plus (UI Components)
- Axios (API Requests)
- Server-Sent Events (Streaming)

**Backend**
- Node.js + Express
- Anthropic SDK (@anthropic-ai/sdk)
- CORS Middleware
- File System Logging

**AI Models**
- Claude Sonnet 4 (Primary)
- Claude 3.5 Sonnet (Fallback)

### Data Flow Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Frontend (Vue 3)                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Translation  ‚îÇ  Function Ball    ‚îÇ  Translation Controls      ‚îÇ
‚îÇ Workspace    ‚îÇ  Analysis Panel   ‚îÇ  - Quality selection (3)   ‚îÇ
‚îÇ - Input text ‚îÇ  - 6 balls        ‚îÇ  - Requirement inputs      ‚îÇ
‚îÇ - Direction  ‚îÇ  - Group settings ‚îÇ  - Translate button        ‚îÇ
‚îÇ - Results    ‚îÇ  - Real-time prog ‚îÇ                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì  API Requests
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Pinia Store (State Management)               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ - analysisForTranslation: Store analysis results             ‚îÇ
‚îÇ - storeAnalysisForTranslation(): Incremental accumulation    ‚îÇ
‚îÇ - getAnalysisForTranslation(): Text consistency validation   ‚îÇ
‚îÇ - translateText(): Translation API call                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì  HTTP/SSE
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Backend (Express API)                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ /translate/  ‚îÇ /analyze-with-   ‚îÇ  Logging System            ‚îÇ
‚îÇ claude       ‚îÇ balls-streaming  ‚îÇ  - Request interceptor     ‚îÇ
‚îÇ              ‚îÇ                  ‚îÇ  - Response interceptor    ‚îÇ
‚îÇ - Quality    ‚îÇ  - Grouped       ‚îÇ  - Log persistence         ‚îÇ
‚îÇ   routing    ‚îÇ    processing    ‚îÇ  - /api/logs query         ‚îÇ
‚îÇ - Dynamic    ‚îÇ  - SSE streaming ‚îÇ                            ‚îÇ
‚îÇ   Prompt     ‚îÇ                  ‚îÇ                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì  Anthropic SDK
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Claude API (Anthropic)                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Primary: claude-sonnet-4-20250514                            ‚îÇ
‚îÇ Fallback: claude-3-5-sonnet-20241022                         ‚îÇ
‚îÇ - Temperature: 0.3                                           ‚îÇ
‚îÇ - Max Tokens: 4000                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Performance & Results

### Token Optimization Results

| Scenario | Traditional | Optimized | Savings |
|----------|------------|-----------|---------|
| Standard translation (no existing analysis) | ~450 tokens | ~450 tokens | 0% |
| Standard translation (full existing analysis) | ~900 tokens | ~500 tokens | **~44%** |
| Fast translation (no requirements) | ~280 tokens | ~200 tokens | **~28%** |
| Function ball analysis (6 balls) | Single call | Grouped calls | Concurrent speedup |

### Response Time

- **Fast Mode**: 2-4 seconds
- **Standard Mode (Two-step)**:
  - Step 1 (Analysis): 3-5 seconds
  - Step 2 (Translation): 3-5 seconds
  - Total: 6-10 seconds
- **Function Ball Analysis**:
  - Single ball: 2-3 seconds
  - Grouped (2/group): 3-5 seconds/group

---

## üîë Key Implementation Details

### 1. Prompt Design Principles

**Clear Role Definition**
```
##Role
You are a senior, professional Chinese-Arabic translator who 
pursues faithfulness and fluency, collaborating with translation 
analysis and strategy experts to complete translations.
```

**Task and Workflow Separation**
```
##Task
Strictly follow the original translation requirements, rationally 
reference the report from translation analysis experts, and 
complete the following translation task.

##Workflow
1. Browse and understand the client's original translation requirements.
2. Carefully read and understand the translation expert's report...
3. First literal translation following improved strategy...
4. Review and polish the translation...
```

**Structured Output Enforcement**
```json
##Output Format
Please provide JSON response in the following format:
{
  "translate_advice_rationality": "Whether reasonable, improvements",
  "initial_translation": "First literal translation result",
  "initial_translation_revising_strategy": "Review translation...",
  "revised_translation": "Polished final translation"
}
```

### 2. JSON Parsing with Fallbacks

**Multi-layer Parsing Strategy**

```javascript
function parseClaudeResponse(response, originalText, mode) {
  try {
    // 1. Try JSON format parsing
    const jsonMatch = response.match(/\{[\s\S]*\}/)
    if (jsonMatch) {
      try {
        const jsonData = JSON.parse(jsonMatch[0])
        return parseJsonResponse(jsonData, originalText)
      } catch (jsonError) {
        console.log('JSON parsing failed, trying text parsing')
      }
    }
    
    // 2. Fallback to text format parsing
    return parseTextResponse(response, originalText)
  } catch (error) {
    // 3. Last resort default result
    return {
      translatedText: response.split('\n').find(line => line.trim()) || originalText,
      analysis: { /* default values */ }
    }
  }
}
```

### 3. Frontend Streaming Data Processing

**SSE Parsing with Progress Callbacks**

```javascript
const reader = response.body.getReader()
const decoder = new TextDecoder()
let buffer = ''

while (true) {
  const { done, value } = await reader.read()
  if (done) break
  
  buffer += decoder.decode(value, { stream: true })
  const lines = buffer.split('\n')
  buffer = lines.pop() || '' // Keep incomplete line
  
  for (const line of lines) {
    if (line.startsWith('data: ')) {
      const data = JSON.parse(line.slice(6))
      
      if (onProgress) {
        onProgress(data) // Real-time callback
      }
      
      if (data.type === 'group_complete') {
        // Display group results immediately
        displayGroupResult(data)
        // Store for translation use immediately
        storeAnalysisForTranslation(data.data, text)
      }
    }
  }
}
```

---

## üìà Project Achievements

### Feature Completeness
- ‚úÖ Three quality translation tiers (Fast/Standard/Premium)
- ‚úÖ 6 function ball analysis modules
- ‚úÖ Grouped/streaming analysis execution
- ‚úÖ Analysis reuse mechanism
- ‚úÖ Dynamic prompt assembly
- ‚úÖ Primary+fallback model fault tolerance
- ‚úÖ End-to-end logging system
- ‚úÖ Web-based log viewer

### Code Quality
- **Robustness Score**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
- Comprehensive input validation and error handling
- Clear module separation and function naming
- Complete logging and observability
- Proper reactive data update mechanisms

### Technical Value
1. **Prompt Engineering**: Dynamic assembly, two-step chain, structured output
2. **Cost Optimization**: 30-50% reduction in redundant token consumption
3. **Observability**: End-to-end logging + log viewing API
4. **User Experience**: Streaming returns, real-time progress, analysis reuse
5. **Engineering Robustness**: Primary+fallback models, multi-layer parsing fallbacks, incremental storage

---

## üöÄ Quick Start

### Requirements
- Node.js 16+
- npm or yarn

### Installation & Launch

```bash
# 1. Install all dependencies
npm run install-all

# 2. Configure environment variables
cd backend
cp .env.example .env
# Edit .env to add Claude API Key and Base URL

# 3. Start development server (frontend & backend together)
npm run dev
```

### Access URLs
- Frontend UI: http://localhost:5173
- Backend API: http://localhost:3000
- Log Viewer: http://localhost:3000/api/logs
- Health Check: http://localhost:3000/api/health

---

## üìù API Documentation

### Translation Endpoint

**POST** `/api/translate/claude`

```json
{
  "text": "Hello, world",
  "mode": "zh-ar",
  "requirements": {
    "quality": "standard",
    "intent": "Business communication",
    "reference": "Formal business document",
    "directRequest": "Use formal register"
  },
  "analysisForTranslation": {
    "text_characteristics": "...",
    "terminology_idioms_analysis": {},
    "initial_translation_strategy": "..."
  }
}
```

### Function Ball Analysis Endpoint (Streaming)

**POST** `/api/translate/analyze-with-balls-streaming`

```json
{
  "text": "Welcome to our company",
  "selectedBalls": [
    { "id": "text-features" },
    { "id": "terminology" },
    { "id": "suggestions" }
  ],
  "intent": "Business partners",
  "reference": "",
  "directRequest": "",
  "mode": "zh-ar",
  "groupSize": 2
}
```

**Response (SSE Streaming)**

```
data: {"type":"start","totalGroups":2,"message":"Starting grouped analysis"}

data: {"type":"group_start","groupIndex":1,"ballIds":["text-features","terminology"]}

data: {"type":"group_complete","groupIndex":1,"data":{...},"completedGroups":1}

data: {"type":"group_complete","groupIndex":2,"data":{...},"completedGroups":2}

data: {"type":"complete","mergedResult":{...},"totalGroups":2}
```

### Log Viewing Endpoint

**GET** `/api/logs?date=2025-01-20`

```json
{
  "success": true,
  "data": [
    {
      "timestamp": "2025-01-20T10:30:15.123Z",
      "level": "info",
      "message": "Starting translation",
      "data": {
        "text": "Hello, world",
        "mode": "zh-ar",
        "quality": "standard"
      }
    }
  ]
}
```

---

## üéØ Future Optimization Directions

1. **Fine-grained Analysis Control**
   - User-customizable analysis dimensions
   - Editable and re-optimizable analysis results

2. **Intelligent Prompt Optimization**
   - A/B testing of different prompt structures based on historical data
   - Automatic recording of optimal prompt templates

3. **Caching Mechanism**
   - Translation cache for common text segments
   - Terminology database persistence and automatic learning

4. **Batch Translation**
   - Document upload and batch processing
   - Progress tracking and async notifications

5. **Multi-language Extension**
   - Support for more language pairs (EN-ZH, FR-ZH, etc.)
   - Multi-language prompt template management

---

## üìö Project Documentation

- [README.md](./read.me/README.md) - Project introduction and usage guide
- [DEMO.md](./read.me/DEMO.md) - Feature demonstration
- [DYNAMIC_PROMPT_IMPLEMENTATION.md](./read.me/DYNAMIC_PROMPT_IMPLEMENTATION.md) - Dynamic prompt implementation
- [CLAUDE_RESPONSE_FLOW.md](./read.me/CLAUDE_RESPONSE_FLOW.md) - Claude response parsing flow
- [STANDARD_MODE_TWO_STEP_IMPLEMENTATION.md](./read.me/STANDARD_MODE_TWO_STEP_IMPLEMENTATION.md) - Standard mode two-step implementation
- [TRANSLATION_DIFFERENCES.md](./read.me/TRANSLATION_DIFFERENCES.md) - Translation differences analysis
- [LOG_VIEWING_GUIDE.md](./read.me/LOG_VIEWING_GUIDE.md) - Log viewing guide
- [final-requirements-verification.md](./final-requirements-verification.md) - Requirements verification report

---

## üë®‚Äçüíª Technical Contact

**Project Role**: AI Engineer / Prompt Engineer  
**Key Responsibilities**:
- Prompt Engineering and workflow design
- Analysis reuse architecture design and implementation
- End-to-end logging and observability system
- Token optimization and cost control

**Technical Highlights**:
- ‚ú® Dynamic prompt assembly engine
- üîÑ Two-step translation workflow
- üíæ Analysis reuse mechanism
- üìä End-to-end logging system
- üéØ Quality-tiered strategies

---

## üìÑ License

MIT License

---

**Last Updated**: January 20, 2026  
**Project Version**: v1.0.0

